# Neural Nexus UI

A modern, feature-rich chat interface for [Ollama](https://ollama.ai) - run AI models locally with style.

![Neural Nexus UI](https://img.shields.io/badge/React-18-blue) ![Vite](https://img.shields.io/badge/Vite-6-purple) ![Tailwind](https://img.shields.io/badge/Tailwind-3-cyan) ![License](https://img.shields.io/badge/License-MIT-green)

![Neural Nexus UI Demo](assets/ui_screenshot.gif)

## ‚ú® Features

- **üé® Modern Dark UI** - Beautiful, responsive interface with smooth animations
- **üó£Ô∏è Voice Mode** - Hands-free conversation with speech recognition and text-to-speech
- **üîß Tool Calling** - AI can use tools for calculations, time, URL fetching, and more
- **üìö Knowledge Base** - Attach custom knowledge for context-aware responses
- **üé≠ Personas** - Switch between chat modes (Default, Coder, Writer, Analyst)
- **üßò Zen Mode** - Distraction-free, minimal interface
- **‚öôÔ∏è Advanced Settings** - Full control over model parameters (temperature, top_k, top_p, etc.)
- **üíæ Session Management** - Multiple chat sessions with auto-save using IndexedDB
- **üìé File Attachments** - Upload images, code files, and documents
- **üìÑ Document Processing** - Extract text from PDF, Word (.docx), and Excel (.xlsx) files
- **‚å®Ô∏è Keyboard Shortcuts** - Power user friendly
- **üîÑ Streaming Responses** - Real-time token streaming

## üöÄ Quick Start

### Prerequisites

- [Node.js](https://nodejs.org/) 18+ (or use conda with nodejs)
- [Ollama](https://ollama.ai) running locally

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/neural-nexus-ui.git
cd neural-nexus-ui

# Install dependencies
npm install

# Start development server
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) in your browser.

### Using Conda (Alternative)

```bash
# Create conda environment
conda create -n neural-nexus-ui nodejs=20 -y
conda activate neural-nexus-ui

# Install and run
npm install
npm run dev
```

## üõ†Ô∏è Configuration

### Ollama Setup

Make sure Ollama is running:

```bash
ollama serve
```

Pull a model:

```bash
ollama pull llama3.2
# or
ollama pull deepseek-r1:8b
```

The UI will auto-detect available models.

### Environment

The app connects to Ollama at `http://localhost:11434` by default. You can change this in the Settings panel.

## ‚å®Ô∏è Keyboard Shortcuts

| Shortcut | Action |
|----------|--------|
| `Ctrl/Cmd + K` | New chat |
| `Ctrl/Cmd + B` | Toggle sidebar |
| `Ctrl/Cmd + ,` | Open settings |
| `Ctrl/Cmd + /` | Toggle Zen mode |
| `Enter` | Send message |
| `Shift + Enter` | New line |

## üé≠ Personas

- **Default** - Balanced, general-purpose assistant
- **Coder** - Technical expert for programming tasks
- **Writer** - Creative writing and content assistance
- **Analyst** - Data analysis and structured insights

## üìÅ Project Structure

```
neural-nexus-ui/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ components/       # React components (TypeScript)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Button.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ChatInput.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ChatMessage.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CodeBlock.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ HelpModal.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ KnowledgeBaseModal.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MessageContent.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ModelManagerModal.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ PersonaSelector.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SettingsModal.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Sidebar.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ VoiceModeOverlay.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ WelcomeScreen.tsx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.ts
‚îÇ   ‚îú‚îÄ‚îÄ utils/            # Utility functions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ documents.ts  # PDF/Word/Excel processing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ helpers.ts    # Formatting helpers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ storage.ts    # IndexedDB manager
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.ts
‚îÇ   ‚îú‚îÄ‚îÄ types/            # TypeScript types
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.ts
‚îÇ   ‚îú‚îÄ‚îÄ __tests__/        # Test files
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Button.test.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ helpers.test.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ HelpModal.test.tsx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ setup.ts
‚îÇ   ‚îú‚îÄ‚îÄ App.jsx           # Main application component
‚îÇ   ‚îú‚îÄ‚îÄ main.jsx          # React entry point
‚îÇ   ‚îî‚îÄ‚îÄ index.css         # Global styles & Tailwind
‚îú‚îÄ‚îÄ .nvmrc                # Node version (20)
‚îú‚îÄ‚îÄ .env.example          # Environment template
‚îú‚îÄ‚îÄ index.html            # HTML template
‚îú‚îÄ‚îÄ tsconfig.json         # TypeScript configuration
‚îú‚îÄ‚îÄ vitest.config.ts      # Test configuration
‚îú‚îÄ‚îÄ vite.config.js        # Vite configuration (includes proxy)
‚îú‚îÄ‚îÄ tailwind.config.js    # Tailwind configuration
‚îú‚îÄ‚îÄ postcss.config.js     # PostCSS configuration
‚îî‚îÄ‚îÄ package.json          # Dependencies & scripts
```

## üß™ Development

### Available Scripts

```bash
# Start development server
npm run dev

# Run tests
npm test

# Run tests with UI
npm run test:ui

# Run tests with coverage
npm run test:coverage

# Type check
npm run typecheck

# Build for production
npm run build

# Preview production build
npm run preview
```

## üîß Advanced Model Parameters

Access these in Settings ‚Üí Advanced:

| Parameter | Description | Default |
|-----------|-------------|---------|
| Temperature | Creativity (0-2) | 0.7 |
| Top K | Token selection pool | 40 |
| Top P | Nucleus sampling | 0.9 |
| Repeat Penalty | Reduce repetition | 1.1 |
| Context Length | Token memory | 4096 |
| Max Tokens | Response length | 2048 |
| Mirostat | Perplexity control | Off |

## üß† Memory & Context

### How Context Works

- **Session Memory** - Each chat session maintains full conversation history
- **Context Window** - Limited by `num_ctx` parameter (default: 4096 tokens)
- **Knowledge Base** - Inject persistent context across conversations
- **System Prompts** - Persona-specific instructions sent with each request

### Context Tips

- Use **Knowledge Base** for information you want available across all chats
- Increase `num_ctx` in Advanced Settings for longer conversations (uses more VRAM)
- Start a **New Chat** when switching topics to avoid context pollution
- The model receives: `System Prompt + Knowledge Base + Full Chat History + Your Message`

### Storage

- Sessions are saved to **IndexedDB** (virtually unlimited storage, browser-managed)
- Knowledge Base entries are stored in IndexedDB
- No server-side storage - everything stays local
- Auto-migrates from localStorage to IndexedDB on first load

## üìÑ Document Processing

Neural Nexus can extract text from various document formats for AI analysis:

| Format | Extensions | Processing | Max Size |
|--------|------------|------------|----------|
| **PDF** | `.pdf` | Text extraction from all pages | 100MB |
| **Word** | `.docx`, `.doc` | Full text extraction | 100MB |
| **Excel** | `.xlsx`, `.xls` | CSV conversion per sheet | 100MB |
| **Images** | `.png`, `.jpg`, `.gif`, `.webp` | Sent to multimodal models | 50MB |
| **Code/Text** | `.py`, `.js`, `.md`, `.txt`, etc. | Direct text injection | 25MB |

### How Document Processing Works

1. **CPU-based extraction** - Documents are processed in your browser using JavaScript libraries
2. **Text injection** - Extracted text is injected into the prompt for the LLM
3. **No external services** - All processing happens locally, your documents never leave your machine

### Supported Libraries

- **PDF.js** - Mozilla's PDF rendering library
- **Mammoth** - Word document text extraction
- **SheetJS (xlsx)** - Excel spreadsheet parsing

## üîß Tool Calling (Function Calling)

Neural Nexus supports Ollama's tool calling feature, allowing the AI to use tools for enhanced capabilities.

### Enabling Tools

1. Open **Settings** (`Ctrl/Cmd + ,`)
2. Click **"Show Tools (Function Calling)"**
3. Toggle **"Enable Tool Calling"** on
4. Optionally enable/disable individual tools

### Built-in Tools

| Tool | Description | Example Use |
|------|-------------|-------------|
| `get_current_time` | Get current date/time with timezone support | "What time is it in Tokyo?" |
| `calculate` | Mathematical calculations | "What is 15% of 250?" |
| `random_number` | Generate random numbers | "Give me a random number between 1 and 100" |
| `web_search` | Search the web using DuckDuckGo | "Search for Lexus RX 350 2025 specs" |
| `fetch_url` | Fetch content from a specific URL | "Fetch the content from https://example.com" |
| `encode_text` | Base64/URL encoding/decoding | "Encode this text to base64" |
| `generate_uuid` | Generate UUIDs | "Generate a UUID for me" |
| `text_stats` | Text analysis (word count, etc.) | "How many words are in this paragraph?" |

### Supported Models

Tool calling requires models that support function calling:
- **qwen3** (recommended)
- **llama3.1**, **llama3.2**
- **mistral**
- **granite3-dense**

### How It Works

1. When tools are enabled, tool definitions are sent with your message
2. The model decides if any tools would help answer your question
3. If yes, the model generates tool calls instead of a direct response
4. Neural Nexus executes the tools and sends results back to the model
5. The model generates a final response using the tool results

> **Note:** When tools are enabled, responses use non-streaming mode which may feel slightly slower, but enables the AI to use tools accurately.

## ‚ö†Ô∏è Known Limitations

| Issue | Description | Workaround |
|-------|-------------|------------|
| Voice Mode (Firefox) | Speech recognition not supported | Use Chrome, Edge, or Safari |
| Large Context | May slow down with very long conversations | Start new chat or reduce `num_ctx` |
| Image Support | Only works with multimodal models (llava, etc.) | Use a vision-capable model |
| Token Limit | Responses truncated at `num_predict` tokens | Increase in Advanced Settings |
| CORS Errors | Browser blocks Ollama API | App uses Vite proxy (dev mode) |
| Tool Calling | Only works with compatible models | Use qwen3, llama3.1+, or mistral |

## üêõ Reporting Issues

Found a bug? Please [open an issue](https://github.com/ahjavid/neural-nexus-ui/issues) with:

1. **Description** - What happened vs. what you expected
2. **Steps to Reproduce** - How to trigger the bug
3. **Environment** - Browser, OS, Ollama version, model used
4. **Console Errors** - Open DevTools (F12) ‚Üí Console tab
5. **Screenshots** - If applicable

### Common Issues

<details>
<summary><b>Connection Failed / Can't reach Ollama</b></summary>

1. Make sure Ollama is running: `ollama serve`
2. Check if Ollama responds: `curl http://localhost:11434/api/tags`
3. In dev mode, the Vite proxy handles CORS automatically
4. For production builds, configure Ollama with `OLLAMA_ORIGINS=*`
</details>

<details>
<summary><b>No models available</b></summary>

1. Pull a model first: `ollama pull llama3.2`
2. Click the refresh button next to the model dropdown
3. Check Ollama is running: `ollama list`
</details>

<details>
<summary><b>Voice mode not working</b></summary>

1. Use Chrome, Edge, or Safari (Firefox not supported)
2. Allow microphone permissions when prompted
3. Check browser console for errors (F12)
4. Ensure HTTPS or localhost (required for mic access)
</details>

<details>
<summary><b>Slow responses / High latency</b></summary>

1. Reduce `num_ctx` (context length) in Advanced Settings
2. Use a smaller model (e.g., `llama3.2:1b` instead of `llama3.2:8b`)
3. Check GPU utilization with `ollama ps`
4. Reduce `num_predict` for shorter responses
</details>

## üèóÔ∏è Building for Production

```bash
# Build optimized bundle
npm run build

# Preview production build
npm run preview
```

The build output will be in the `dist/` folder.

> **Note:** Production builds require Ollama to have CORS enabled:
> ```bash
> OLLAMA_ORIGINS=* ollama serve
> ```

## ü§ù Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- [Ollama](https://ollama.ai) - Local LLM runtime
- [React](https://react.dev) - UI framework
- [Vite](https://vitejs.dev) - Build tool
- [Tailwind CSS](https://tailwindcss.com) - Styling
- [Lucide](https://lucide.dev) - Icons
- [PDF.js](https://mozilla.github.io/pdf.js/) - PDF text extraction
- [Mammoth](https://github.com/mwilliamson/mammoth.js) - Word document processing
- [SheetJS](https://sheetjs.com/) - Excel spreadsheet parsing

---

Made with ‚ù§Ô∏è for the local AI community
